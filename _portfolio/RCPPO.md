---
title: "Performance Analysis of Supervised and Unsupervised Machine Learning Models"
excerpt: "This project explores both supervised and unsupervised learning techniques on the Seeds and Obesity datasets (UCI website). In the [supervised learning analysis](https://github.com/venkateshv90/Machine-Learning/tree/main/Supervised), KNN, SVM, and NN models were evaluated. It was found that while all models performed well on the simpler Seeds dataset, the more complex Obesity dataset highlighted SVMâ€™s superior performance. The study underscores how dataset complexity and feature structure impact model efficiency and accuracy. The [unsupervised learning component](https://github.com/venkateshv90/Machine-Learning/tree/main/Unsupervised) applied Expectation Maximization and k-Means clustering models to the two datasets. Dimensionality reduction techniques (PCA, ICA, RP) were also applied to effectively identify the underlying data structures. Notably, dimensionality reduction enhanced NN performance, and integrating clustering insights further refined model accuracy. These findings demonstrate the power of combining supervised and unsupervised approaches for comprehensive data analysis"
collection: portfolio
---

This is project 1




In this project I implemented the [Reward Constrained Policy Optimization Paper](https://openreview.net/pdf?id=SkfrvsA9FX) by Tessler et al. into stable-baselines3 implementation of PPO. Additionally, I reproduced the original results by tracking my experiments using weights and biases. The code for this project can be found [here](https://github.com/sudo-Boris/stable-baselines3). I also wrote an article elaborating on the theory of RCPO and my results and submitted it to the ICLR Blogposts Track! You can fin the article [here](https://iclr-blogposts.github.io/staging/blog/2023/Adaptive-Reward-Penalty-in-Safe-Reinforcement-Learning/)
